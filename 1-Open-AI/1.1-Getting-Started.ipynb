{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c059e2c",
   "metadata": {},
   "source": [
    "#### Getting started With Langchain And Open AI\n",
    "\n",
    "In this quickstart we'll see how to:\n",
    "\n",
    "- Get setup with LangChain, LangSmith and LangServe\n",
    "- Use the most basic and common components of LangChain: prompt templates, models, and output parsers.\n",
    "- Build a simple application with LangChain\n",
    "- Trace your application with LangSmith\n",
    "- Serve your application with LangServe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d1b4be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "## Langsmith Tracking\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGSMITH_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = os.getenv(\"LANGCHAIN_PROJECT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fb31163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x10febd060>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x11868efb0>, root_client=<openai.OpenAI object at 0x107713250>, root_async_client=<openai.AsyncOpenAI object at 0x11868eef0>, model_name='gpt-4o', model_kwargs={}, openai_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\") ## Specify the model\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "675d5368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello! I'm just a program, so I don't have feelings, but I'm here and ready to help you with anything you need. How can I assist you today?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 33, 'prompt_tokens': 13, 'total_tokens': 46, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_07871e2ad8', 'id': 'chatcmpl-C3PlpJXtqScxZMHz8hx11E0WSZqi8', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--7e910784-67f5-4718-8b08-b30371f4d1bd-0', usage_metadata={'input_tokens': 13, 'output_tokens': 33, 'total_tokens': 46, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Input and get response from LLM\n",
    "response = llm.invoke(\"Hello, how are you?\") ## Invoke the model.\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4d63c72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI Engineer. Provide me answers based on the questions'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Chat Prompt template\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are an expert AI Engineer. Provide me answers based on the questions\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])\n",
    "chat_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2db412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Langsmith is a tool and platform developed by LangChain, aimed at enhancing the development and deployment of applications that utilize large language models (LLMs). It provides a suite of features designed to streamline the creation, testing, and monitoring of LLM-powered applications. The key capabilities of Langsmith include:\\n\\n1. **Development Environment**: Langsmith offers an integrated environment to build and experiment with language model applications. This supports rapid prototyping and iteration.\\n\\n2. **Testing Suite**: The platform includes tools for robust testing of LLM apps, including evaluation frameworks for measuring model performance, debugging capabilities, and testing under various scenarios to ensure reliability.\\n\\n3. **Deployment and Monitoring**: Langsmith facilitates easy deployment of applications while providing tools to monitor their performance in real-time, allowing developers to track usage, identify issues, and optimize their models efficiently.\\n\\n4. **Integration with LangChain**: Since Langsmith is part of the LangChain ecosystem, it seamlessly integrates with LangChain's tools and frameworks, providing a comprehensive solution for managing the entire lifecycle of LLM applications.\\n\\nOverall, Langsmith aims to simplify and enhance the process of working with complex language models, making it easier for developers to create sophisticated and reliable AI applications.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 246, 'prompt_tokens': 33, 'total_tokens': 279, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_ff25b2783a', 'id': 'chatcmpl-C3PlrFL5imGwf4mwGT1ZR8N5Y1aT4', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--15b09e8b-7d83-45c0-8c13-cbd77b777112-0', usage_metadata={'input_tokens': 33, 'output_tokens': 246, 'total_tokens': 279, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain=chat_prompt|llm ## Create a chain from the chat prompt and the language model\n",
    "response=chain.invoke({\"input\": \"Can you tell me about Langsmith?\"})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "271524db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e98839e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Langsmith is a development toolkit designed to assist in the launch and management of LLM (Large Language Model) applications. It offers several features to streamline the development process and improve the performance of these applications. Some of its key functionalities include:\n",
      "\n",
      "1. **Trace and Error Analysis:** Langsmith provides the ability to trace requests and debug errors, allowing developers to optimize their applications efficiently.\n",
      "\n",
      "2. **Evaluation of Application Outputs:** It offers tools to evaluate the outputs of LLM applications, ensuring they meet the desired quality and performance standards.\n",
      "\n",
      "3. **Integration Capabilities:** Langsmith can be integrated into custom applications or popular frameworks like LangChain. This flexibility allows developers to leverage Langsmithâ€™s capabilities across different project environments.\n",
      "\n",
      "Overall, Langsmith aims to facilitate the creation and maintenance of robust LLM applications by offering tools tailored to the unique challenges faced in this domain.\n"
     ]
    }
   ],
   "source": [
    "## stroutput Parser\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser = StrOutputParser()\n",
    "chain=chat_prompt|llm|output_parser ## Create a chain with output parser\n",
    "response=chain.invoke({\"input\": \"Can you tell me about Langsmith?\"})\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
